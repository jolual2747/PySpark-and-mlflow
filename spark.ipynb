{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, MinMaxScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages  org.apache.spark:spark-avro_2.12:3.4.1,io.delta:delta-core_2.12:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/07/10 23:24:21 WARN Utils: Your hostname, DESKTOP-JKDOQO9 resolves to a loopback address: 127.0.1.1; using 172.26.19.142 instead (on interface eth0)\n",
      "23/07/10 23:24:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/josealcocer27/.local/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/josealcocer27/.ivy2/cache\n",
      "The jars for the packages stored in: /home/josealcocer27/.ivy2/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-72ef704e-ec74-4d66-914d-a263d5db1020;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.4.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 261ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.4.1 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-72ef704e-ec74-4d66-914d-a263d5db1020\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/6ms)\n",
      "23/07/10 23:24:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Spark_ML\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('delta')\\\n",
    "    .load('delta/saber11')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/10 23:24:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10361"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lenguaje: string (nullable = true)\n",
      " |-- matematicas: string (nullable = true)\n",
      " |-- sociales: string (nullable = true)\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- filosofia: string (nullable = true)\n",
      " |-- biologia: string (nullable = true)\n",
      " |-- quimica: string (nullable = true)\n",
      " |-- fisica: string (nullable = true)\n",
      " |-- nivel_ingles: string (nullable = true)\n",
      " |-- sisben: integer (nullable = true)\n",
      " |-- estrato: integer (nullable = true)\n",
      " |-- genero: string (nullable = true)\n",
      " |-- puntaje_saber11: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values at column lenguaje\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|lenguaje|\n",
      "+--------+\n",
      "|    bajo|\n",
      "|   medio|\n",
      "|superior|\n",
      "|    alto|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Unique values at column matematicas\n",
      "\n",
      "+-----------+\n",
      "|matematicas|\n",
      "+-----------+\n",
      "|       bajo|\n",
      "|      medio|\n",
      "|   superior|\n",
      "|       alto|\n",
      "+-----------+\n",
      "\n",
      "\n",
      "Unique values at column sociales\n",
      "\n",
      "+--------+\n",
      "|sociales|\n",
      "+--------+\n",
      "|    bajo|\n",
      "|   medio|\n",
      "|superior|\n",
      "|    alto|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Unique values at column filosofia\n",
      "\n",
      "+---------+\n",
      "|filosofia|\n",
      "+---------+\n",
      "|     bajo|\n",
      "|    medio|\n",
      "| superior|\n",
      "|     alto|\n",
      "+---------+\n",
      "\n",
      "\n",
      "Unique values at column biologia\n",
      "\n",
      "+--------+\n",
      "|biologia|\n",
      "+--------+\n",
      "|    bajo|\n",
      "|   medio|\n",
      "|superior|\n",
      "|    alto|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Unique values at column quimica\n",
      "\n",
      "+--------+\n",
      "| quimica|\n",
      "+--------+\n",
      "|    bajo|\n",
      "|   medio|\n",
      "|superior|\n",
      "|    alto|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Unique values at column fisica\n",
      "\n",
      "+--------+\n",
      "|  fisica|\n",
      "+--------+\n",
      "|    bajo|\n",
      "|superior|\n",
      "|   medio|\n",
      "|    alto|\n",
      "+--------+\n",
      "\n",
      "\n",
      "Unique values at column nivel_ingles\n",
      "\n",
      "+------------+\n",
      "|nivel_ingles|\n",
      "+------------+\n",
      "|          A2|\n",
      "|          A-|\n",
      "|          B1|\n",
      "|          B+|\n",
      "|          A1|\n",
      "+------------+\n",
      "\n",
      "\n",
      "Unique values at column sisben\n",
      "\n",
      "+------+\n",
      "|sisben|\n",
      "+------+\n",
      "|     1|\n",
      "|     3|\n",
      "|    -9|\n",
      "|     5|\n",
      "|     4|\n",
      "|     2|\n",
      "+------+\n",
      "\n",
      "\n",
      "Unique values at column estrato\n",
      "\n",
      "+-------+\n",
      "|estrato|\n",
      "+-------+\n",
      "|      1|\n",
      "|      6|\n",
      "|      3|\n",
      "|      5|\n",
      "|      4|\n",
      "|      2|\n",
      "+-------+\n",
      "\n",
      "\n",
      "Unique values at column genero\n",
      "\n",
      "+------+\n",
      "|genero|\n",
      "+------+\n",
      "|Hombre|\n",
      "| Mujer|\n",
      "+------+\n",
      "\n",
      "\n",
      "Unique values at column puntaje_saber11\n",
      "\n",
      "+---------------+\n",
      "|puntaje_saber11|\n",
      "+---------------+\n",
      "|           bajo|\n",
      "|          medio|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if column != 'Id':\n",
    "        print(f'\\nUnique values at column {column}\\n')\n",
    "        df.select(column).distinct().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id')\n",
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('puntaje_saber11',\n",
    "                   when(col('puntaje_saber11')=='bajo', 0)\\\n",
    "                   .otherwise(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced or imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|puntaje_saber11|count|\n",
      "+---------------+-----+\n",
      "|              1| 7140|\n",
      "|              0| 3221|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"puntaje_saber11\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|puntaje_saber11|count|\n",
      "+---------------+-----+\n",
      "|              1| 3219|\n",
      "|              0| 3221|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_0 = df.groupBy(\"puntaje_saber11\").count().sort(asc(\"puntaje_saber11\")).collect()[0][1]\n",
    "class_1 = df.groupBy(\"puntaje_saber11\").count().sort(asc(\"puntaje_saber11\")).collect()[1][1]\n",
    "\n",
    "# Find the ratio of the class sizes\n",
    "class_ratio = class_0 / class_1 \n",
    "\n",
    "# Define the sampling fractions for each class\n",
    "sampling_fractions = {\n",
    "    0: 1.0,  # No sampling for class 0 (majority class)\n",
    "    1: class_ratio  # Sampling based on class ratio for class 1 (minority class)\n",
    "}\n",
    "\n",
    "balanced_df = df.sampleBy(\"puntaje_saber11\", fractions=sampling_fractions, seed=1234)\n",
    "balanced_df.groupBy(\"puntaje_saber11\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Indexer, OneHotEncoder and MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for OHE and MinMaxScaler\n",
    "\n",
    "OHE_cols = [x[0] for x in df.dtypes if x[1] == 'string' and x[0] != 'puntaje_saber11']\n",
    "to_scale = [x[0] for x in df.dtypes if x[1] in ['int', 'float'] and x[0] != 'puntaje_saber11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+--------------------------+-----------------------+------------------------+-----------------------+----------------------+---------------------+---------------------------+---------------------+--------------------+--------------------+\n",
      "|puntaje_saber11|lenguaje_encoded_scaled|matematicas_encoded_scaled|sociales_encoded_scaled|filosofia_encoded_scaled|biologia_encoded_scaled|quimica_encoded_scaled|fisica_encoded_scaled|nivel_ingles_encoded_scaled|genero_encoded_scaled|       sisben_scaled|      estrato_scaled|\n",
      "+---------------+-----------------------+--------------------------+-----------------------+------------------------+-----------------------+----------------------+---------------------+---------------------------+---------------------+--------------------+--------------------+\n",
      "|              0|          [1.0,0.0,0.0]|             [1.0,0.0,0.0]|          [1.0,0.0,0.0]|           [1.0,0.0,0.0]|          [0.0,1.0,0.0]|         [0.0,1.0,0.0]|            (3,[],[])|              (4,[0],[1.0])|                [1.0]|[0.7857142857142857]|               [0.4]|\n",
      "|              0|          [0.0,1.0,0.0]|                 (3,[],[])|          [0.0,1.0,0.0]|           [1.0,0.0,0.0]|          [0.0,1.0,0.0]|         [1.0,0.0,0.0]|        [0.0,1.0,0.0]|              (4,[0],[1.0])|                [1.0]|[0.7142857142857142]|               [0.0]|\n",
      "|              0|          [0.0,1.0,0.0]|             [0.0,1.0,0.0]|          [0.0,1.0,0.0]|           [0.0,1.0,0.0]|          [0.0,1.0,0.0]|         [0.0,1.0,0.0]|        [1.0,0.0,0.0]|              (4,[0],[1.0])|                [0.0]|               [1.0]|               [0.4]|\n",
      "|              0|          [0.0,1.0,0.0]|             [0.0,1.0,0.0]|          [0.0,1.0,0.0]|           [1.0,0.0,0.0]|          [0.0,1.0,0.0]|         [1.0,0.0,0.0]|        [0.0,1.0,0.0]|              (4,[2],[1.0])|                [1.0]|               [1.0]|[0.6000000000000001]|\n",
      "|              0|          [0.0,1.0,0.0]|             [0.0,1.0,0.0]|          [0.0,1.0,0.0]|           [1.0,0.0,0.0]|          [0.0,1.0,0.0]|         [0.0,1.0,0.0]|        [0.0,1.0,0.0]|              (4,[0],[1.0])|                [1.0]|[0.7142857142857142]|               [0.0]|\n",
      "+---------------+-----------------------+--------------------------+-----------------------+------------------------+-----------------------+----------------------+---------------------+---------------------------+---------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple Indexers for every column in OHE_cols\n",
    "indexer = [StringIndexer(inputCol = col, outputCol = col+'_indexed') for col in OHE_cols]\n",
    "\n",
    "# Multiple OHE for every column in OHE_cols\n",
    "encoder = [OneHotEncoder(inputCol = col+'_indexed', outputCol = col+'_encoded') for col in OHE_cols]\n",
    "\n",
    "aux_features = [col+'_encoded' for col in OHE_cols] + to_scale\n",
    "\n",
    "# Vector Assembler to can apply MinMaxScaler\n",
    "vector_to_scale = [VectorAssembler(inputCols = [col], outputCol = col+'_vec') for col in aux_features]\n",
    "scaler = [MinMaxScaler(inputCol = col+'_vec', outputCol = col+'_scaled') for col in aux_features]\n",
    "\n",
    "# Final Vector Assembler\n",
    "vector = VectorAssembler(inputCols = [col+'_scaled' for col in aux_features], outputCol ='features')\n",
    "\n",
    "transform_steps = indexer + encoder + vector_to_scale + scaler\n",
    "\n",
    "# Pipeline\n",
    "features_pipeline = Pipeline(stages = transform_steps)\n",
    "df_trans = features_pipeline.fit(balanced_df).transform(balanced_df)\n",
    "to_select = [col for col in df_trans.columns if '_scaled' in col or col == 'puntaje_saber11']\n",
    "df_trans.select(to_select).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testingData) = balanced_df.randomSplit([0.70, 0.3], seed = 1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/10 23:25:00 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/07/10 23:25:00 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2023/07/10 23:25:00 INFO mlflow.tracking.fluent: Experiment with name 'saber11' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/josealcocer27/git-projects/PySpark-and-mlflow/mlruns/1', creation_time=1689049500078, experiment_id='1', last_update_time=1689049500078, lifecycle_stage='active', name='saber11', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(experiment_name='saber11')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a function to create ROC curve that can be reused multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(roc):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(roc['FPR'],roc['TPR'])\n",
    "    plt.ylabel('False Positive Rate')\n",
    "    plt.xlabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/10 23:26:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "2023/07/10 23:26:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpk_9axsfp/model, flavor: spark), fall back to return ['pyspark==3.4.1']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "# to_vector = to_select\n",
    "# to_vector.append('puntaje_saber11')\n",
    "mlflow.spark.autolog(disable=True)\n",
    "with mlflow.start_run(run_name = 'log_reg_baseline'):\n",
    "    # define model and set a tag\n",
    "    model_lr = LogisticRegression(featuresCol = 'features', labelCol = 'puntaje_saber11')\n",
    "    mlflow.set_tag('model_name', str(model_lr.__class__.__name__))\n",
    "\n",
    "    # define pipeline and fit\n",
    "    pipeline_lr = Pipeline(stages = [features_pipeline, vector, model_lr])\n",
    "    lr_model = pipeline_lr.fit(trainingData)\n",
    "    trainingSummary = lr_model.stages[-1].summary\n",
    "\n",
    "    # evaluate and log metrics and model\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol = 'probability', labelCol = 'puntaje_saber11')\n",
    "    trainPredictions = lr_model.transform(trainingData)\n",
    "    trainAUC = evaluator.evaluate(trainPredictions)\n",
    "    testPredictions = lr_model.transform(testingData)\n",
    "    testAUC = evaluator.evaluate(testPredictions)\n",
    "    mlflow.log_metrics({\"train AUC\": trainAUC, \"test AUC\": testAUC, \"training accuracy\": trainingSummary.accuracy,\n",
    "                        \"training weighted precision\": trainingSummary.weightedPrecision, \n",
    "                        \"training weighted recall\": trainingSummary.weightedRecall})\n",
    "    mlflow.spark.log_model(lr_model, 'log_reg_spark')\n",
    "    roc = trainingSummary.roc.toPandas()\n",
    "    fig = plot_roc(roc)\n",
    "    mlflow.log_figure(fig, \"ROC_training_curve.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'predictionCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb Cell 24\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m paramGridSVM \u001b[39m=\u001b[39m ParamGridBuilder()\\\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m.\u001b[39maddGrid(svc_model\u001b[39m.\u001b[39mregParam, [\u001b[39m0.01\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m])\\\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m.\u001b[39maddGrid(svc_model\u001b[39m.\u001b[39mmaxIter, [\u001b[39m100\u001b[39m, \u001b[39m150\u001b[39m])\\\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m.\u001b[39mbuild()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# create an evaluator\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m evaluator \u001b[39m=\u001b[39m BinaryClassificationEvaluator(predictionCol\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m'\u001b[39;49m, labelCol\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpuntaje_saber11\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# create cross validator for tuning\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m crossvalSVM \u001b[39m=\u001b[39m CrossValidator(estimator \u001b[39m=\u001b[39m svc_model,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                             estimatorParamMaps \u001b[39m=\u001b[39m paramGridSVM,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                             evaluator \u001b[39m=\u001b[39m evaluator,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/josealcocer27/git-projects/PySpark-and-mlflow/spark.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m                             numFolds \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMethod \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m forces keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_kwargs \u001b[39m=\u001b[39m kwargs\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'predictionCol'"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name = 'Linear_SVM_with_grid'):    \n",
    "    # define model and set a tag\n",
    "    svc_model = LinearSVC(featuresCol='features', labelCol='puntaje_saber11')\n",
    "    mlflow.set_tag('model_name', str(svc_model.__class__.__name__))\n",
    "\n",
    "    # build parameter grid\n",
    "    paramGridSVM = ParamGridBuilder()\\\n",
    "        .addGrid(svc_model.regParam, [0.01, 0.5, 1, 5])\\\n",
    "        .addGrid(svc_model.maxIter, [100, 150])\\\n",
    "        .build()\n",
    "\n",
    "    # create an evaluator\n",
    "    evaluator = BinaryClassificationEvaluator(predictionCol='prediction', labelCol='puntaje_saber11')\n",
    "\n",
    "    # create cross validator for tuning\n",
    "    crossvalSVM = CrossValidator(estimator = svc_model,\n",
    "                                estimatorParamMaps = paramGridSVM,\n",
    "                                evaluator = evaluator,\n",
    "                                numFolds = 3)\n",
    "\n",
    "    # define pipeline with stages and train it\n",
    "    pipeline = Pipeline(stages=[features_pipeline, vector, crossvalSVM])\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # evaluate and log metrics and best model\n",
    "    predictions = model.transform(testingData)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    best_model = model.stages[-1].bestModel\n",
    "    mlflow.log_metric(\"AUC\", accuracy)\n",
    "    mlflow.log_params(params={\"RegParam\": best_model.getRegParam(), \"maxIter\": best_model.getMaxIter()})\n",
    "    mlflow.spark.log_model(best_model, \"SparkLinearSVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.stages[-1].bestModel.summary\n",
    "\n",
    "BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LinearSVCModel.summary of LinearSVCModel: uid=LinearSVC_fa8e13bb2dc2, numClasses=2, numFeatures=28>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].bestModel.getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testingData) = df.randomSplit([0.70, 0.3])\n",
    "lr_model = pipeline_lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+----------------------------------------+----------+\n",
      "|features                                                                   |probability                             |prediction|\n",
      "+---------------------------------------------------------------------------+----------------------------------------+----------+\n",
      "|(28,[0,3,6,10,12,15,18,22,25],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |[0.25516373223123756,0.7448362677687624]|1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |[0.25516373223123756,0.7448362677687624]|1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |[0.25516373223123756,0.7448362677687624]|1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |[0.25516373223123756,0.7448362677687624]|1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |[0.25516373223123756,0.7448362677687624]|1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])              |[0.2490534978895824,0.7509465021104176] |1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])              |[0.2490534978895824,0.7509465021104176] |1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])              |[0.2490534978895824,0.7509465021104176] |1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.2])|[0.2774940436960577,0.7225059563039423] |1.0       |\n",
      "|(28,[0,3,6,10,12,15,18,22,25,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.2])|[0.2774940436960577,0.7225059563039423] |1.0       |\n",
      "+---------------------------------------------------------------------------+----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_summary = lr_model.stages[2].summary.predictions\n",
    "lr_summary = lr_summary.select('features', 'probability' ,'prediction')\n",
    "lr_summary.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lr_model.transform(testingData).withColumnRenamed(\"puntaje_saber11\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779062299293513"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = 'prediction', labelCol = 'label')\n",
    "evaluator.evaluate(test,  {evaluator.metricName: \"accuracy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
